#!/usr/bin/env python3
"""
Paper Summarizer Bot ã®å˜ä½“ãƒ†ã‚¹ãƒˆãƒ»å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®Discordã«æ¥ç¶šã™ã‚‹å‰ã«åŸºæœ¬æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import os
import sys
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append('bots')
sys.path.append('bots/paper_summarizer')

from bots.paper_summarizer.bot import PaperDatabase, PaperSummarizer, AICodeReviewer

async def test_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    db = PaperDatabase("test_papers.db")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_paper = {
        'arxiv_id': '2024.00001',
        'title': 'Test Paper: A Novel Approach to Testing',
        'authors': 'Test Author, Another Author',
        'abstract': 'This is a test abstract for testing purposes.',
        'published_date': '2024-01-01',
        'summary': 'This is a test summary.'
    }
    
    # è«–æ–‡ã‚’ä¿å­˜
    paper_id = db.save_paper(test_paper)
    print(f"âœ… è«–æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸ (ID: {paper_id})")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    is_processed = db.is_paper_processed('2024.00001')
    print(f"âœ… é‡è¤‡ãƒã‚§ãƒƒã‚¯: {is_processed}")
    
    # æ–°ã—ã„è«–æ–‡ã®ãƒã‚§ãƒƒã‚¯
    is_new = db.is_paper_processed('2024.00002')
    print(f"âœ… æ–°ã—ã„è«–æ–‡ãƒã‚§ãƒƒã‚¯: {not is_new}")
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove("test_papers.db")
    print("ğŸ—‘ï¸  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

async def test_summarizer():
    """AIè¦ç´„æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§  AIè¦ç´„ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    summarizer = PaperSummarizer(api_key)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è«–æ–‡æƒ…å ±
    test_title = "Attention Is All You Need"
    test_abstract = """
    The dominant sequence transduction models are based on complex recurrent or 
    convolutional neural networks that include an encoder and a decoder. The best 
    performing models also connect the encoder and decoder through an attention 
    mechanism. We propose a new simple network architecture, the Transformer, 
    based solely on attention mechanisms, dispensing with recurrence and convolutions 
    entirely.
    """
    
    try:
        summary = await summarizer.summarize_paper(test_title, test_abstract)
        print("âœ… è¦ç´„ç”ŸæˆæˆåŠŸ:")
        print(f"ğŸ“ {summary[:200]}...")
    except Exception as e:
        print(f"âŒ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

async def test_rss_parsing():
    """RSSè§£æã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“¡ RSSè§£æãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    import feedparser
    
    # arXiv CS.AI ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒ†ã‚¹ãƒˆ
    rss_url = "http://export.arxiv.org/rss/cs.AI"
    
    try:
        print(f"ğŸ” RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ä¸­: {rss_url}")
        feed = await asyncio.to_thread(feedparser.parse, rss_url)
        
        if feed.entries:
            print(f"âœ… {len(feed.entries)} ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—")
            
            # æœ€åˆã®ã‚¨ãƒ³ãƒˆãƒªã®è©³ç´°ã‚’è¡¨ç¤º
            first_entry = feed.entries[0]
            print(f"ğŸ“„ æœ€æ–°è«–æ–‡:")
            print(f"   ã‚¿ã‚¤ãƒˆãƒ«: {first_entry.title[:80]}...")
            print(f"   ID: {first_entry.id.split('/')[-1]}")
            print(f"   å…¬é–‹æ—¥: {first_entry.published}")
            print(f"   è‘—è€…æ•°: {len(first_entry.authors) if hasattr(first_entry, 'authors') else 'N/A'}")
        else:
            print("âŒ ã‚¨ãƒ³ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
    except Exception as e:
        print(f"âŒ RSSè§£æã‚¨ãƒ©ãƒ¼: {e}")

async def test_discord_embed():
    """Discord Embedå½¢å¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ’¬ Discord Embed ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # Embedã®æ§‹é€ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    embed_data = {
        'title': 'Test Paper: A Novel Approach to Testing',
        'url': 'https://arxiv.org/abs/2024.00001',
        'description': 'ğŸ”¬ **ç ”ç©¶æ¦‚è¦**: ãƒ†ã‚¹ãƒˆç”¨ã®è«–æ–‡ã§ã™\nğŸ’¡ **æŠ€è¡“çš„è²¢çŒ®**: æ–°ã—ã„ãƒ†ã‚¹ãƒˆæ‰‹æ³•\nğŸš€ **å®Ÿç”¨æ€§**: é–‹ç™ºè€…å‘ã‘',
        'color': 0x0099ff,
        'fields': [
            {'name': 'ğŸ“ è‘—è€…', 'value': 'Test Author, Another Author'},
            {'name': 'ğŸ”— arXiv ID', 'value': '2024.00001'},
            {'name': 'ğŸ“… å…¬é–‹æ—¥', 'value': '2024-01-01'}
        ]
    }
    
    print("âœ… Discord Embed æ§‹é€ :")
    print(f"   ã‚¿ã‚¤ãƒˆãƒ«: {embed_data['title']}")
    print(f"   URL: {embed_data['url']}")
    print(f"   èª¬æ˜: {embed_data['description'][:50]}...")
    print(f"   ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(embed_data['fields'])}")

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("ğŸš€ Paper Summarizer Bot ãƒ†ã‚¹ãƒˆé–‹å§‹\n")
    
    # å„æ©Ÿèƒ½ã‚’é †ç•ªã«ãƒ†ã‚¹ãƒˆ
    await test_database()
    await test_rss_parsing()
    await test_discord_embed()
    await test_summarizer()  # API ã‚­ãƒ¼ãŒå¿…è¦ãªã®ã§æœ€å¾Œ
    
    print("\nâœ… å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. .env ãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªAPIã‚­ãƒ¼ã‚’è¨­å®š")
    print("2. Discord Bot ã‚’ä½œæˆã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—")
    print("3. Discord ã‚µãƒ¼ãƒãƒ¼ã« #paper-summaries ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä½œæˆ")
    print("4. python bots/paper_summarizer/bot.py ã§å®Ÿè¡Œ")

if __name__ == "__main__":
    asyncio.run(main())