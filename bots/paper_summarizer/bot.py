"""
è«–æ–‡è¦ç´„ RSS Bot
arXiv ãªã©ã® RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç›£è¦–ã—ã€æ–°ã—ã„è«–æ–‡ã‚’è¦ç´„ã—ã¦ Discord ã«æŠ•ç¨¿
"""

import asyncio
import sqlite3
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import feedparser
import openai
import discord
from discord.ext import commands, tasks
import os
import sys

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ import ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from base_bot import BaseBot, BaseBotConfig, setup_base_bot

class PaperSummarizerConfig(BaseBotConfig):
    """è«–æ–‡è¦ç´„ Bot ã®è¨­å®š"""
    def __init__(self):
        super().__init__()
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.rss_urls = os.getenv('ARXIV_RSS_URLS', '').split(',')
        self.summary_channel_name = 'paper-summaries'
        self.check_interval_hours = 6  # 6æ™‚é–“ã”ã¨ã«ãƒã‚§ãƒƒã‚¯

class PaperDatabase:
    """è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†"""
    
    def __init__(self, db_path: str = "papers.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS papers (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                arxiv_id TEXT UNIQUE NOT NULL,
                title TEXT NOT NULL,
                authors TEXT NOT NULL,
                abstract TEXT NOT NULL,
                published_date TEXT NOT NULL,
                summary TEXT,
                discord_message_id TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def is_paper_processed(self, arxiv_id: str) -> bool:
        """è«–æ–‡ãŒæ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT id FROM papers WHERE arxiv_id = ?', (arxiv_id,))
        result = cursor.fetchone()
        
        conn.close()
        return result is not None
    
    def save_paper(self, paper_data: Dict) -> int:
        """è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO papers (arxiv_id, title, authors, abstract, published_date, summary)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            paper_data['arxiv_id'],
            paper_data['title'],
            paper_data['authors'],
            paper_data['abstract'],
            paper_data['published_date'],
            paper_data['summary']
        ))
        
        paper_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return paper_id

class PaperSummarizer:
    """è«–æ–‡è¦ç´„ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
    
    async def summarize_paper(self, title: str, abstract: str) -> str:
        """è«–æ–‡ã‚’è¦ç´„"""
        prompt = f"""
ä»¥ä¸‹ã® AI/ML è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚
é–‹ç™ºè€…ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‘ã‘ã«ã€æŠ€è¡“çš„ãªãƒã‚¤ãƒ³ãƒˆã¨å®Ÿç”¨æ€§ã‚’é‡è¦–ã—ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}

ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ: {abstract}

è¦ç´„ã¯ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
ğŸ”¬ **ç ”ç©¶æ¦‚è¦**: [1-2æ–‡ã§ç ”ç©¶ã®æ ¸å¿ƒã‚’èª¬æ˜]
ğŸ’¡ **æŠ€è¡“çš„è²¢çŒ®**: [æ–°ã—ã„æ‰‹æ³•ã‚„æ”¹å–„ç‚¹ã‚’èª¬æ˜]
ğŸš€ **å®Ÿç”¨æ€§**: [é–‹ç™ºè€…ã«ã¨ã£ã¦ã®æ„ç¾©ã‚„å¿œç”¨å¯èƒ½æ€§]
ğŸ“Š **çµæœ**: [ä¸»è¦ãªå®Ÿé¨“çµæœã‚„æ€§èƒ½å‘ä¸Š]
"""
        
        try:
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

class PaperSummarizerBot(BaseBot):
    """è«–æ–‡è¦ç´„ Bot ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        config = PaperSummarizerConfig()
        super().__init__(config)
        
        self.db = PaperDatabase()
        self.summarizer = PaperSummarizer(config.openai_api_key) if config.openai_api_key else None
        self.summary_channel = None
        
        # RSS ãƒã‚§ãƒƒã‚¯ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        if not self.check_rss_feeds.is_running():
            self.check_rss_feeds.start()
    
    async def on_ready(self):
        """Bot èµ·å‹•æ™‚ã®å‡¦ç†"""
        await super().on_ready()
        
        # è¦ç´„ãƒãƒ£ãƒ³ãƒãƒ«ã‚’å–å¾—
        for guild in self.guilds:
            channel = discord.utils.get(guild.channels, name=self.config.summary_channel_name)
            if channel:
                self.summary_channel = channel
                self.logger.info(f'è¦ç´„ãƒãƒ£ãƒ³ãƒãƒ«ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ: {channel.name}')
                break
        
        if not self.summary_channel:
            self.logger.warning(f'è¦ç´„ãƒãƒ£ãƒ³ãƒãƒ« "{self.config.summary_channel_name}" ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
    
    @tasks.loop(hours=6)  # 6æ™‚é–“ã”ã¨ã«å®Ÿè¡Œ
    async def check_rss_feeds(self):
        """RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æ–°ã—ã„è«–æ–‡ã‚’å‡¦ç†"""
        if not self.summarizer or not self.summary_channel:
            self.logger.warning('è¦ç´„æ©Ÿèƒ½ã¾ãŸã¯ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
            return
        
        self.logger.info('RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...')
        
        for rss_url in self.config.rss_urls:
            if not rss_url.strip():
                continue
                
            try:
                await self.process_rss_feed(rss_url.strip())
                # ãƒ•ã‚£ãƒ¼ãƒ‰é–“ã§å°‘ã—å¾…æ©Ÿ
                await asyncio.sleep(5)
            except Exception as e:
                self.logger.error(f'RSS ãƒ•ã‚£ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({rss_url}): {e}')
    
    @check_rss_feeds.before_loop
    async def before_check_rss_feeds(self):
        """RSS ãƒã‚§ãƒƒã‚¯ã‚¿ã‚¹ã‚¯é–‹å§‹å‰ã®å¾…æ©Ÿ"""
        await self.wait_until_ready()
        # Botèµ·å‹•å¾Œã€å°‘ã—å¾…ã£ã¦ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        await asyncio.sleep(30)
    
    async def process_rss_feed(self, rss_url: str):
        """å˜ä¸€ã® RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å‡¦ç†"""
        try:
            # RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’éåŒæœŸã§å–å¾—
            feed = await asyncio.to_thread(feedparser.parse, rss_url)
            
            if not hasattr(feed, 'entries') or not feed.entries:
                self.logger.warning(f'RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã«ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“: {rss_url}')
                return
            
            self.logger.info(f'RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ {len(feed.entries)} ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—: {rss_url}')
            new_papers_count = 0
            
            for entry in feed.entries[:3]:  # æœ€æ–°3ä»¶ã®ã¿å‡¦ç†ï¼ˆè² è·è»½æ¸›ï¼‰
                try:
                    # arXiv ID ã‚’æŠ½å‡º
                    if not hasattr(entry, 'id') or not entry.id:
                        continue
                    
                    arxiv_id = entry.id.split('/')[-1].split('v')[0]  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ã‚’é™¤å»
                    
                    # æ—¢ã«å‡¦ç†æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
                    if self.db.is_paper_processed(arxiv_id):
                        continue
                    
                    # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèª
                    if not all([hasattr(entry, attr) for attr in ['title', 'summary', 'published']]):
                        self.logger.warning(f'å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {arxiv_id}')
                        continue
                    
                    # è‘—è€…æƒ…å ±ã‚’å®‰å…¨ã«å–å¾—
                    authors = "Unknown"
                    if hasattr(entry, 'authors') and entry.authors:
                        try:
                            authors = ', '.join([author.name for author in entry.authors])
                        except:
                            authors = str(entry.authors)
                    
                    # è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                    paper_data = {
                        'arxiv_id': arxiv_id,
                        'title': entry.title.strip(),
                        'authors': authors,
                        'abstract': entry.summary.strip(),
                        'published_date': entry.published,
                        'summary': ''
                    }
                    
                    # è¦ç´„ã‚’ç”Ÿæˆ
                    self.logger.info(f'è«–æ–‡è¦ç´„ã‚’ç”Ÿæˆä¸­: {paper_data["title"][:50]}...')
                    summary = await self.summarizer.summarize_paper(
                        paper_data['title'], 
                        paper_data['abstract']
                    )
                    paper_data['summary'] = summary
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    paper_id = self.db.save_paper(paper_data)
                    
                    # Discord ã«æŠ•ç¨¿
                    await self.post_paper_summary(paper_data)
                    
                    new_papers_count += 1
                    self.logger.info(f'æ–°ã—ã„è«–æ–‡ã‚’å‡¦ç†ã—ã¾ã—ãŸ: {paper_data["title"][:50]}...')
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
                    await asyncio.sleep(3)
                    
                except Exception as e:
                    self.logger.error(f'è«–æ–‡å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({arxiv_id if "arxiv_id" in locals() else "unknown"}): {e}')
                    continue
            
            if new_papers_count > 0:
                self.logger.info(f'{new_papers_count} ä»¶ã®æ–°ã—ã„è«–æ–‡ã‚’å‡¦ç†ã—ã¾ã—ãŸ')
            else:
                self.logger.info('æ–°ã—ã„è«–æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
                
        except Exception as e:
            self.logger.error(f'RSS ãƒ•ã‚£ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({rss_url}): {e}')
    
    async def post_paper_summary(self, paper_data: Dict):
        """è«–æ–‡è¦ç´„ã‚’ Discord ã«æŠ•ç¨¿"""
        try:
            # ã‚¿ã‚¤ãƒˆãƒ«ã®é•·ã•åˆ¶é™
            title = paper_data['title'][:250] + "..." if len(paper_data['title']) > 250 else paper_data['title']
            
            # è¦ç´„ã®é•·ã•åˆ¶é™
            summary = paper_data['summary'][:2000] + "..." if len(paper_data['summary']) > 2000 else paper_data['summary']
            
            embed = discord.Embed(
                title=title,
                url=f"https://arxiv.org/abs/{paper_data['arxiv_id']}",
                description=summary,
                color=discord.Color.blue(),
                timestamp=datetime.now()
            )
            
            # è‘—è€…æƒ…å ±ï¼ˆé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ï¼‰
            authors = paper_data['authors'][:500] + "..." if len(paper_data['authors']) > 500 else paper_data['authors']
            embed.add_field(
                name="ğŸ“ è‘—è€…", 
                value=authors, 
                inline=False
            )
            
            embed.add_field(
                name="ğŸ”— arXiv ID", 
                value=paper_data['arxiv_id'], 
                inline=True
            )
            
            # å…¬é–‹æ—¥ã®å®‰å…¨ãªå‡¦ç†
            try:
                pub_date = paper_data['published_date'][:10] if paper_data['published_date'] else "ä¸æ˜"
            except:
                pub_date = "ä¸æ˜"
            
            embed.add_field(
                name="ğŸ“… å…¬é–‹æ—¥", 
                value=pub_date, 
                inline=True
            )
            
            embed.set_footer(text="AI Forge Paper Summarizer")
            
            message = await self.summary_channel.send(embed=embed)
            
            # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”¨ï¼‰
            await message.add_reaction('ğŸ‘')  # æœ‰ç”¨
            await message.add_reaction('ğŸ¤”')  # å¾®å¦™
            await message.add_reaction('â¤ï¸')  # ç´ æ™´ã‚‰ã—ã„
            
            self.logger.info(f'Discord ã«æŠ•ç¨¿å®Œäº†: {paper_data["arxiv_id"]}')
            
        except discord.HTTPException as e:
            self.logger.error(f'Discord HTTP ã‚¨ãƒ©ãƒ¼: {e}')
        except Exception as e:
            self.logger.error(f'Discord æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}')

# ã‚³ãƒãƒ³ãƒ‰ç¾¤
class PaperCommands(commands.Cog):
    """è«–æ–‡é–¢é€£ã‚³ãƒãƒ³ãƒ‰"""
    
    def __init__(self, bot: PaperSummarizerBot):
        self.bot = bot
    
    @discord.app_commands.command(name="check_papers", description="æ‰‹å‹•ã§ RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯")
    async def check_papers(self, interaction: discord.Interaction):
        """æ‰‹å‹•ã§è«–æ–‡ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        await interaction.response.defer()
        
        if not self.bot.summarizer:
            await interaction.followup.send("âŒ OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        await interaction.followup.send("ğŸ” RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        try:
            await self.bot.check_rss_feeds()
            await interaction.followup.send("âœ… RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
        except Exception as e:
            await interaction.followup.send(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    bot = PaperSummarizerBot()
    
    # åŸºæœ¬æ©Ÿèƒ½ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    await setup_base_bot(bot)
    
    # è«–æ–‡é–¢é€£ã‚³ãƒãƒ³ãƒ‰ã‚’è¿½åŠ 
    await bot.add_cog(PaperCommands(bot))
    
    # Bot ã‚’å®Ÿè¡Œ
    bot.run_bot()

if __name__ == "__main__":
    asyncio.run(main())